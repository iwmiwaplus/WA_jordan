{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c668e1-3647-489f-92d6-84df9273fea3",
   "metadata": {},
   "source": [
    "## ET correction using wofs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad2138-908e-45ab-8503-d70d8a9e32d7",
   "metadata": {},
   "source": [
    "##### 1 - Reproject DEA wofs Projection coordinate system to Geography coordinate system by using QGIS\n",
    "##### 2 - Apply 0.75 threshold to wofs for extracting reservoirs\n",
    "##### 3 - Create nc using wofs_mask rasters\n",
    "##### 4 - Download GLEAM nc global dataset from s3 bucket\n",
    "##### 5 - Create daily tif files using GLEAM global nc\n",
    "##### 6 - Clip global tif to Africa extend\n",
    "##### 7 - Time conversion daily to monthly\n",
    "##### 8 - Create GLEAM nc as a single file using monthly tif\n",
    "##### 9 - Download global SSEBop from s3 bucket\n",
    "##### 10- Clip to Africa extend and rename the file\n",
    "##### 11 - Apply ET correction for the SSEBop using GLEAM ET and WOFS mask ncs\n",
    "\n",
    "##### Note - Time range 2003 - 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de457494-fcf9-45d9-87f2-364515c9ea89",
   "metadata": {},
   "source": [
    "#### 2 - Apply 0.75 threshold to wofs for extracting reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231514d-15b0-4e44-b3a2-9d82b57f91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import time\n",
    "\n",
    "wofs_folder = r'/efs/CWA/rs_input_tifs/wofs/wofs_reproject'\n",
    "output_folder = r'/efs/CWA/rs_input_tifs/wofs/wofs_mask'\n",
    "wofs_fhs = glob.glob(os.path.join(wofs_folder, '*.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e0d61-cb61-4c13-9058-3740eb2bc459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fh in sorted(wofs_fhs):\n",
    "    start = time.time()\n",
    "    filename = fh.split('/')[-1]\n",
    "    \n",
    "    dataset = rasterio.open(fh)\n",
    "\n",
    "    profile = {'driver': 'GTiff', 'dtype': 'float32', 'nodata': -9999, 'width':dataset.shape[1],                   \n",
    "               'height':dataset.shape[0] , 'count': 1, 'crs': dataset.crs, 'transform': dataset.transform,\n",
    "               'compress':'lzw', 'num_threads':'all_cpus', 'blockxsize':128, 'blockysize':128, 'tiled':True}\n",
    "    \n",
    "    data = dataset.read(1)\n",
    "    wofs_nw = xr.where(data >= 0.75, 1, np.nan)\n",
    "    wofs_nw = wofs_nw.astype('float32')\n",
    "    \n",
    "    outpath = os.path.join(output_folder, filename)\n",
    "    \n",
    "    with rasterio.open(outpath, \"w\", **profile) as dst:\n",
    "        dst.write(wofs_nw, indexes=1)\n",
    "\n",
    "    print(outpath)\n",
    "    end = time.time()\n",
    "    print('Total time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be319459-8719-4b7a-84cc-3c08230a36ee",
   "metadata": {},
   "source": [
    "#### 3 - create nc using wofs_mask rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aec24c-be67-4129-ba24-9dceffd7c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% netCDF files from\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.append(r'/efs/CWA/scripts')\n",
    "import createNC_cmi_v5 as createNC_cmi\n",
    "# import  createNC_cmi\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "basedir = r\"/efs/CWA/rs_input_tifs\"\n",
    "pathwatermask = os.path.join(basedir, 'wofs', '3_wofs_mask')\n",
    "\n",
    "template = r\"/efs/CWA/static_datasets/template/L1_LCC_21_Resample_1km_correct_nodata.tif\"\n",
    "\n",
    "shp_path = r\"/efs/CWA/static_datasets/shapefile/Africa_adm0_buffer.shp\"\n",
    "save_location = r\"/efs/CWA/netcdf_files_test\"\n",
    "\n",
    "\n",
    "name = 'AFR'\n",
    "\n",
    "datasets = {                   \n",
    "                     'wofs'  :   [pathwatermask,\n",
    "                                  ('time','latitude', 'longitude'), \n",
    "                                  {'units': 'None', 'source': 'DEA', 'quantity':'WOFS'}]\n",
    "          }\n",
    "\n",
    "nc_files = []\n",
    "\n",
    "for d in datasets:\n",
    "    filesAll = glob.glob(os.path.join(datasets[d][0],'*.tif'))\n",
    "    dataset = {d: datasets[d]}\n",
    "    fname = name+'_'+datasets[d][2]['quantity']+'_'+ datasets[d][2]['source']+'.nc'\n",
    "    nc_file = os.path.join(save_location, fname)\n",
    "    nc_files.append(nc_file)\n",
    "    succes = createNC_cmi.make_netcdf(nc_file, dataset, shp_path, template, name)\n",
    "    \n",
    "end = time.time()\n",
    "print('\\n',end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff08cbc-24cd-455b-a6b2-09aeb6c02bd6",
   "metadata": {},
   "source": [
    "#### 4 - Download GLEAM nc global dataset from s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49068065-172c-45d4-b5cc-931c2345a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "years = np.arange(2003,2022)\n",
    "for i in years:\n",
    "    # print(i)\n",
    "    source = 's3://iwmi-wa/Mansoor_ec2_data/data_from_sftp/v3.6a/daily/{}/Ep_{}_GLEAM_v3.6a.nc'.format(i, i)\n",
    "    disti = '/efs/CWA/rs_input_tifs/GLEAM/nc_global/Ep_{}_GLEAM_v3.6a.nc'.format(i)\n",
    "    cmd = 'aws s3 cp {} {}'.format(source, disti) \n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc9e99-1bf7-48d0-8633-856b4c2be08d",
   "metadata": {},
   "source": [
    "#### 5 - Create daily tif files using GLEAM global nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f5aa6-5047-452e-8a31-e633a33cd264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import gdal\n",
    "import osr\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "def Save_as_tiff(name='', data='', geo='', projection=''):\n",
    "    \"\"\"\n",
    "    This function save the array as a geotiff\n",
    "\n",
    "    Keyword arguments:\n",
    "    name -- string, directory name\n",
    "    data -- [array], dataset of the geotiff\n",
    "    geo -- [minimum lon, pixelsize, rotation, maximum lat, rotation,\n",
    "            pixelsize], (geospatial dataset)\n",
    "    projection -- integer, the EPSG code\n",
    "    \"\"\"\n",
    "    \n",
    "    # save as a geotiff\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = driver.Create(name, int(data.shape[1]), int(data.shape[0]), 1, gdal.GDT_Float32, ['COMPRESS=LZW'])\n",
    "    srse = osr.SpatialReference()\n",
    "    if projection == '':\n",
    "        srse.SetWellKnownGeogCS(\"WGS84\")\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            if not srse.SetWellKnownGeogCS(projection) == 6:\n",
    "                srse.SetWellKnownGeogCS(projection)\n",
    "            else:\n",
    "                try:\n",
    "                    srse.ImportFromEPSG(int(projection))\n",
    "                except:\n",
    "                    srse.ImportFromWkt(projection)\n",
    "        except:\n",
    "            try:\n",
    "                srse.ImportFromEPSG(int(projection))\n",
    "            except:\n",
    "                srse.ImportFromWkt(projection)\n",
    "\n",
    "    dst_ds.SetProjection(srse.ExportToWkt())\n",
    "    dst_ds.GetRasterBand(1).SetNoDataValue(-9999)\n",
    "    dst_ds.SetGeoTransform(geo)\n",
    "    dst_ds.GetRasterBand(1).WriteArray(data)\n",
    "    dst_ds = None\n",
    "    return()\n",
    "\n",
    "\n",
    "nc_files = glob.glob(r'/efs/CWA/rs_input_tifs/GLEAM/nc_global/*.nc')\n",
    "output_tif = r\"/efs/CWA/rs_input_tifs/GLEAM/daily\"\n",
    "parameter = 'Ep'\n",
    "\n",
    "for fh in sorted(nc_files):    \n",
    "    nc_data = xr.open_dataset(fh)    \n",
    "\n",
    "    data_range = nc_data['time'][:].values\n",
    "    \n",
    "    for i in data_range:\n",
    "        str_date = datetime.strptime(str(i),'%Y-%m-%dT%H:%M:%S.%f000').strftime(\"%Y.%m.%d\")\n",
    "        print(str_date)\n",
    "        \n",
    "        bottom_left_x = nc_data['lon'][0].values\n",
    "        bottom_left_y = nc_data['lat'][0].values\n",
    "        cellsize1 = 0.25\n",
    "        cellsize2 = -0.25\n",
    "        data = nc_data[list(nc_data.keys())[0]][0].values\n",
    "        data[np.isnan(data)] = -9999\n",
    "    \n",
    "\n",
    "        geo = [bottom_left_x, cellsize1, 0, bottom_left_y, 0, cellsize2]\n",
    "        geotif = r'{}/{}_GLEAM_global_v3.6a_mm.day_{}.tif'.format(output_tif, parameter, str_date)\n",
    "        print(geotif)\n",
    "        Save_as_tiff(name=geotif, data=data, geo=geo, projection=\"WGS84\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf7be4-6f4b-4df1-a70f-77cbe72c3619",
   "metadata": {},
   "source": [
    "#### 6 - Clip global tif to Africa extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6316e8c-7b72-4ba2-a394-ceaba08e73b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shapefile\n",
    "import glob\n",
    "import watertools.General.raster_conversions as RC\n",
    "import watertools.General.data_conversions as DC\n",
    "\n",
    "### OPTION 2: Read from shapefile\n",
    "# BASIN_SHP = r\"C:\\_WA\\Ethiopia\\shp\\riftvalley_lakes_basin_10km_buff.shp\" #path to Basin shapefile\n",
    "\n",
    "# shape=shapefile.Reader(BASIN_SHP)\n",
    "# xmin,ymin,xmax,ymax=shape.bbox\n",
    "\n",
    "path = r'/efs/CWA/rs_input_tifs/GLEAM/daily'\n",
    "output_path = r'/efs/CWA/rs_input_tifs/GLEAM/daily_AFR'\n",
    "\n",
    "filesAll = glob.glob(os.path.join(path,'*.tif'))\n",
    "\n",
    "for file in sorted(filesAll):\n",
    "    latlim=[-36,38]\n",
    "    lonlim=[-20,54]\n",
    "    filename = file.split(\"/\")[-1]\n",
    "    \n",
    "    filepath = os.path.join(output_path, filename.replace('global', 'AFR'))\n",
    "    \n",
    "    data, geo, proj = RC.clip_data(file, latlim, lonlim)\n",
    "    print(filepath)    \n",
    "    # # Save the file as tiff\n",
    "    DC.Save_as_tiff(name=filepath, data=data, geo=geo, projection='WGS84')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbcf62-010a-4771-ae38-e48aad1bf759",
   "metadata": {},
   "source": [
    "#### 7 - Time conversion daily to monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13030912-88cb-46d0-9c8e-56251ef260b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from watertools.Functions.Time_Conversions import Day_to_monthly_flux as DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b89f3-2f4f-4dfa-9f28-5328c4deaa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import gdal\n",
    "import calendar\n",
    "\n",
    "\n",
    "def Nearest_Interpolate(Dir_in, Startdate, Enddate, format_in = None, format_out = None, Dir_out = None, AOI = None):\n",
    "    \"\"\"\n",
    "    This functions calculates monthly tiff files based on the daily tiff files.\n",
    "    (will calculate the total sum)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Dir_in : str\n",
    "        Path to the input data\n",
    "    Startdate : str\n",
    "        Contains the start date of the model 'yyyy-mm-dd'\n",
    "    Enddate : str\n",
    "        Contains the end date of the model 'yyyy-mm-dd'\n",
    "    Dir_out : str\n",
    "        Path to the output data, default is same as Dir_in\n",
    "\n",
    "    \"\"\"\n",
    "    # import WA+ modules\n",
    "    import watertools.General.data_conversions as DC\n",
    "    import watertools.General.raster_conversions as RC\n",
    "\n",
    "    # Change working directory\n",
    "    os.chdir(Dir_in)\n",
    "\n",
    "    # Define end and start date\n",
    "    Dates = pd.date_range(Startdate, Enddate, freq='MS')\n",
    "\n",
    "    # Find all monthly files\n",
    "    if format_in == None:\n",
    "        files = glob.glob('*.tif')\n",
    "        #files = glob.glob('*daily*.tif')        \n",
    "    else:\n",
    "        files = glob.glob(format_in.replace(\":02d\",\"\").format(yyyy= \"*\", mm = \"*\", dd = \"*\"))    \n",
    "\n",
    "    \n",
    "    # Get array information and define projection\n",
    "    geo_out, proj, size_X, size_Y = RC.Open_array_info(files[0])\n",
    "    if int(proj.split('\"')[-2]) == 4326:\n",
    "        proj = \"WGS84\"\n",
    "\n",
    "    # Get the No Data Value\n",
    "    dest = gdal.Open(files[0])\n",
    "    NDV = dest.GetRasterBand(1).GetNoDataValue()\n",
    "\n",
    "    # Define output directory\n",
    "    if Dir_out is None:\n",
    "\t     Dir_out = Dir_in\n",
    "\n",
    "    if not os.path.exists(Dir_out):\n",
    "\t     os.makedirs(Dir_out)\n",
    "\n",
    "    # loop over the months and sum the days\n",
    "    for date in Dates:\n",
    "        Year = date.year\n",
    "        Month = date.month\n",
    "        if format_in == None:\n",
    "            files_one_year = glob.glob('*%d.%02d*.tif' % (Year, Month))\n",
    "            #files_one_year = glob.glob('*daily*%d.%02d*.tif' % (Year, Month))\n",
    "        else:\n",
    "            files_one_year = glob.glob(format_in.replace(\":02d\",\"\").format(yyyy=Year, mm = \"%02d\" %Month, dd = \"*\"))\n",
    "\n",
    "        # Create empty arrays\n",
    "        Month_data = np.zeros([size_Y, size_X])\n",
    "\n",
    "        # Get amount of days in month\n",
    "        Amount_days_in_month = int(calendar.monthrange(Year, Month)[1])\n",
    "\n",
    "        if len(files_one_year) is not Amount_days_in_month:\n",
    "            print(\"One day is missing!!! month %s year %s\" %(Month, Year))\n",
    "            print(\"Days found = %d\" %len(files_one_year))\n",
    "\n",
    "        for file_one_year in files_one_year:\n",
    "            file_path = os.path.join(Dir_in, file_one_year)\n",
    "\n",
    "            Day_data = RC.Open_tiff_array(file_path)\n",
    "            Day_data[np.isnan(Day_data)] = 0.0\n",
    "            Day_data[Day_data == -9999] = 0.0\n",
    "            Month_data += Day_data\n",
    "            \n",
    "        if str(type(AOI)) == \"<class 'numpy.ndarray'>\":\n",
    "            Month_data = Month_data * AOI\n",
    "            \n",
    "        # Define output name\n",
    "        if format_out == None:  \n",
    "            # file_name = file_one_year.split('_')[0] + '_monthly_' + file_one_year.split('_')[-1] \n",
    "            file_name = file_one_year.replace('mm.day', 'mm.month')\n",
    "            output_name = os.path.join(Dir_out, 'monthly', file_name)\n",
    "            # output_name = os.path.join(Dir_out, file_one_year\n",
    "            #                            .replace('daily', 'monthly')\n",
    "            #                            .replace('day', 'month'))\n",
    "    \n",
    "            output_name = output_name[:-14] + '%d.%02d.01.tif' % (date.year, date.month)\n",
    "        else:\n",
    "            output_name = os.path.join(Dir_out, format_out.format(yyyy = date.year,  mm = date.month, dd = 1))\n",
    "\n",
    "        # Save tiff file\n",
    "        DC.Save_as_tiff(output_name, Month_data, geo_out, proj)\n",
    "        print(output_name)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2b6a51-29a1-48b4-b5e0-248d5ce35aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Dir_in = r'/efs/CWA/rs_input_tifs/GLEAM/daily_AFR'\n",
    "Startdate = '2003-01-01'\n",
    "Enddate = '2021-12-31'\n",
    "Dir_out = r'/efs/CWA/rs_input_tifs/GLEAM/'\n",
    "\n",
    "Nearest_Interpolate(Dir_in, Startdate, Enddate, Dir_out=Dir_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37077b1c-8ab2-4270-8cab-9cf58f3024ee",
   "metadata": {},
   "source": [
    "##### 8 - Create GLEAM nc as a single file using monthly tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c9720-10f5-4a76-a485-de83ddd236c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% netCDF files from\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.append(r'/efs/CWA/scripts')\n",
    "import createNC_cmi_v5 as createNC_cmi\n",
    "# import  createNC_cmi\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "basedir = r\"/efs/CWA/rs_input_tifs\"\n",
    "pathGLEAM = os.path.join(basedir,'GLEAM','monthly')\n",
    "\n",
    "template = r\"/efs/CWA/static_datasets/template/L1_LCC_21_Resample_1km_correct_nodata.tif\"\n",
    "\n",
    "shp_path = r\"/efs/CWA/static_datasets/shapefile/Africa_adm0_buffer.shp\"\n",
    "save_location = r\"/efs/CWA/netcdf_files_test\"\n",
    "\n",
    "\n",
    "name = 'Africa'\n",
    "\n",
    "datasets = {                   \n",
    "                     'ETref'  :   [pathGLEAM,\n",
    "                                  ('time','latitude', 'longitude'), \n",
    "                                  {'units': 'mm.month', 'source': 'GLEAM', 'quantity':'ETref'}]\n",
    "          }\n",
    "\n",
    "nc_files = []\n",
    "\n",
    "for d in datasets:\n",
    "    filesAll = glob.glob(os.path.join(datasets[d][0],'*.tif'))\n",
    "    dataset = {d: datasets[d]}\n",
    "    fname = name+'_'+datasets[d][2]['quantity']+'_'+ datasets[d][2]['source']+'.nc'\n",
    "    nc_file = os.path.join(save_location, fname)\n",
    "    nc_files.append(nc_file)\n",
    "    succes = createNC_cmi.make_netcdf(nc_file, dataset, shp_path, template, name)\n",
    "    \n",
    "end = time.time()\n",
    "print('\\n',end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7e895-c375-4150-9271-4a1ae01062b4",
   "metadata": {},
   "source": [
    "##### 9 - Download global SSEBop from s3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab19c9-92c0-4709-9220-a756db302a4a",
   "metadata": {},
   "source": [
    "##### SSEBop download using aws cli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52563609-cf97-4232-830e-1a5fdd07bc09",
   "metadata": {},
   "source": [
    "##### 10- Clip to Africa extend and rename the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ea3e9-7244-4b99-bc6f-67e718610a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shapefile\n",
    "import glob\n",
    "import watertools.General.raster_conversions as RC\n",
    "import watertools.General.data_conversions as DC\n",
    "from tqdm import tqdm\n",
    "### OPTION 2: Read from shapefile\n",
    "# BASIN_SHP = r\"C:\\_WA\\Ethiopia\\shp\\riftvalley_lakes_basin_10km_buff.shp\" #path to Basin shapefile\n",
    "\n",
    "# shape=shapefile.Reader(BASIN_SHP)\n",
    "# xmin,ymin,xmax,ymax=shape.bbox\n",
    "\n",
    "path = r'/efs/CWA/rs_input_tifs/ET/SSEBop/global'\n",
    "output_path = r'/efs/CWA/rs_input_tifs/ET/SSEBop/AFR'\n",
    "\n",
    "filesAll = glob.glob(os.path.join(path,'*.tif'))\n",
    "\n",
    "for file in tqdm(sorted(filesAll)):\n",
    "    latlim=[-36,38]\n",
    "    lonlim=[-20,54]\n",
    "    filename = file.split(\"/\")[-1]\n",
    "    year = filename.split('.')[0].split('_')[0][1:5]\n",
    "    month = filename.split('.')[0].split('_')[0][5:]\n",
    "    nw_filename = 'SSEBopETv5_actual_mm_monthly_{}.{}.01.tif'.format(year, month)\n",
    "    filepath = os.path.join(output_path, nw_filename)\n",
    "    \n",
    "    data, geo, proj = RC.clip_data(file, latlim, lonlim)\n",
    "    # print(filepath)    \n",
    "    # # Save the file as tiff\n",
    "    DC.Save_as_tiff(name=filepath, data=data, geo=geo, projection='WGS84')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95372be5-b3cc-4799-9b4e-f45186633618",
   "metadata": {},
   "source": [
    "#### 11 - Create SSEBop nc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b0ca0-1f62-48a8-87e4-43bb67ae8c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% netCDF files from\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.append(r'/efs/CWA/scripts')\n",
    "import createNC_cmi_v5 as createNC_cmi\n",
    "# import  createNC_cmi\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "basedir = r\"/efs/CWA/rs_input_tifs\"\n",
    "pathSSEBop = os.path.join(basedir,'ET', 'SSEBop','AFR')\n",
    "\n",
    "template = r\"/efs/CWA/static_datasets/template/L1_LCC_21_Resample_1km_correct_nodata.tif\"\n",
    "\n",
    "shp_path = r\"/efs/CWA/static_datasets/shapefile/Africa_adm0_buffer.shp\"\n",
    "save_location = r\"/efs/CWA/netcdf_files_test\"\n",
    "\n",
    "\n",
    "name = 'AFR'\n",
    "\n",
    "datasets = {                   \n",
    "                     'ETref'  :   [pathSSEBop,\n",
    "                                  ('time','latitude', 'longitude'), \n",
    "                                  {'units': 'mm.month', 'source': 'SSEBop', 'quantity':'ETa'}]\n",
    "          }\n",
    "\n",
    "nc_files = []\n",
    "\n",
    "for d in datasets:\n",
    "    filesAll = glob.glob(os.path.join(datasets[d][0],'*.tif'))\n",
    "    dataset = {d: datasets[d]}\n",
    "    fname = name+'_'+datasets[d][2]['quantity']+'_'+ datasets[d][2]['source']+'.nc'\n",
    "    nc_file = os.path.join(save_location, fname)\n",
    "    nc_files.append(nc_file)\n",
    "    succes = createNC_cmi.make_netcdf(nc_file, dataset, shp_path, template, name)\n",
    "    \n",
    "end = time.time()\n",
    "print('\\n',end - start) #5306.594389677048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3351542-c314-4119-821e-a27d1eca6b40",
   "metadata": {},
   "source": [
    "#### 11 - Resample yearly wofs to monthly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87affbd2-2819-4757-85d2-3f5e337811ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "def open_nc(input_nc, chunksize=None, layer=None):\n",
    "    if chunksize is None:\n",
    "        dts=xr.open_dataset(input_nc)\n",
    "    else:\n",
    "        dts=xr.open_dataset(input_nc,\n",
    "                            chunks={'time':chunksize[0],\n",
    "                                    'longitude':chunksize[1],\n",
    "                                    'latitude':chunksize[2]})\n",
    "    if type(layer) is int: #select dataarray by index\n",
    "        layer_name=list(dts.keys())[layer]\n",
    "        return dts[layer_name]\n",
    "    elif type(layer) is str: #select dataarray by name\n",
    "        return dts[layer]\n",
    "    else:\n",
    "        return dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b4172-9144-40d8-ba79-c1a978cd622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_to_monthly_dataset(yearly_nc, sample_nc,\n",
    "                                start_month=0,\n",
    "                                output=None,\n",
    "                                chunksize=None):\n",
    "    '''\n",
    "    yearly_nc: a yearly dataset to resample to monthly\n",
    "    sample_nc: a monthly dataset to sample 'time' dimension\n",
    "    start_month: the index of start month. \n",
    "        default start_month = 0 means yearly value resample from the first\n",
    "        month in sample_nc\n",
    "                \n",
    "    Resample a yearly netCDF dataset to monthly netCDF dataset\n",
    "    Where the value of each month is the same with the value of the year\n",
    "    '''\n",
    "    dts1=open_nc(yearly_nc,chunksize=chunksize,layer=0)\n",
    "    dts2=open_nc(sample_nc,chunksize=chunksize,layer=0)  \n",
    "   \n",
    "    for i in range(len(dts1.time)):\n",
    "        for t in range(i*12-start_month,i*12+12-start_month):\n",
    "            LU=dts1.isel(time=i)\n",
    "            if t==0:\n",
    "                dts=LU\n",
    "            else:\n",
    "                dts = xr.concat([dts, LU], dim='time')  \n",
    "    dts['time']=dts2['time']\n",
    "    #change coordinates order to [time,latitude,longitude]\n",
    "    dts=dts.transpose('time','latitude','longitude')               \n",
    "\n",
    "    dts.attrs=dts1.attrs\n",
    "    dts.name = dts1.name\n",
    "    \n",
    "    comp = dict(zlib=True, \n",
    "                # complevel=9, \n",
    "                least_significant_digit=2, \n",
    "                chunksizes=chunksize)\n",
    "    if output is None:\n",
    "        output=yearly_nc.replace('.nc','_resampled_monthly.nc')\n",
    "    encoding = {dts.name: comp}\n",
    "    # dts.load().to_netcdf(output,encoding=encoding)\n",
    "    dts.to_netcdf(output,encoding=encoding)\n",
    "    ######\n",
    "    dts1.close()\n",
    "    dts2.close()\n",
    "    print('Save monthly LU datacube as {0}'.format(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c442dcc2-f656-4f6b-b0f7-ba54124bdbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client.dashboard_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d9c56-6aea-4367-bf79-cde7a47096dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WOFS_nc = r'/efs/CWA/netcdf_files_test/AFR_WOFS_DEA.nc'\n",
    "sample_nc = r'/efs/CWA/netcdf_files_test/Africa_ETref_GLEAM.nc'\n",
    "chunksize = [1, 900, 900]\n",
    "monthly_nc = resample_to_monthly_dataset(WOFS_nc, sample_nc,\n",
    "                                start_month=0,\n",
    "                                output=None,\n",
    "                                chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f33597c-98ba-4156-a3d6-dceb6c5667cb",
   "metadata": {},
   "source": [
    "##### 11 - Apply ET correction for the SSEBop using GLEAM ET and WOFS mask ncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82274dee-482d-4808-8ee4-8a9e07242086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "def open_nc(nc,timechunk=1,chunksize=1000):\n",
    "    dts=xr.open_dataset(nc)\n",
    "    key=list(dts.keys())[0]\n",
    "    if 'time' in list(dts.dims.keys()):\n",
    "        var=dts[key].chunk({\"time\": timechunk, \"latitude\": chunksize, \"longitude\": chunksize}) #.ffill(\"time\")\n",
    "    else:\n",
    "        var=dts[key].chunk({\"latitude\": chunksize, \"longitude\": chunksize}) #.ffill(\"time\")        \n",
    "    return var,key\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aet_path = r'/efs/CWA/netcdf_files_test/AFR_ETa_SSEBop.nc'\n",
    "    ret_path = r'/efs/CWA/netcdf_files_test/Africa_ETref_GLEAM.nc'\n",
    "    watermask_path = r'/efs/CWA/netcdf_files_test/AFR_WOFS_DEA_resampled_monthly.nc'\n",
    "    \n",
    "    aet, _ = open_nc(aet_path)\n",
    "    ret, _ = open_nc(ret_path)\n",
    "    mask, _ = open_nc(watermask_path)\n",
    "    # nw_mask = mask.squeeze('time')\n",
    "    # nw_mask = nw_mask.drop('time')\n",
    "    # nw_mask = nw_mask.expand_dims(time=aet.time)\n",
    "           \n",
    "    corrected_et = xr.where(mask==1,ret*0.75,aet)\n",
    "    \n",
    "    ### Write netCDF files\n",
    "    root_f = os.path.dirname(aet_path)    \n",
    "    attrs={'units': 'mm/month', 'source': 'SSEBop', 'quantity':'ETa'}\n",
    "    \n",
    "    corrected_et.attrs=attrs\n",
    "    corrected_et.name = 'SSEBop'\n",
    "    chunks=[1,900,900]\n",
    "    comp = dict(zlib=True, complevel=9, least_significant_digit=2, chunksizes=chunks)\n",
    "    print(\"\\n\\nwriting the Monthly corrected ET netcdf file using water mask\\n\\n\")\n",
    "    et_correct_nc = os.path.join(root_f, 'AFR_ETa_SSEBop_wofs_corrected.nc')\n",
    "    encoding = {\"SSEBop\": comp}\n",
    "    with ProgressBar():\n",
    "        corrected_et.to_netcdf(et_correct_nc, encoding=encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb390d-4705-4032-84ac-d20fd6ffd95c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
